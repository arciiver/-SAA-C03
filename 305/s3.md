# S3

- IF u want to replicate existing objects, use S3 Batch Replication

- There is no **"chaining"** of replication:
  - If bucket 1 has replication into bucket 2, which has replication into bucket 3
  - Then objects created in bucket 1 are **not** replicated to bucket 3

# S3 Storage Classes

- **Amazon S3 Standard** – General Purpose - **Use Case: Big data analytics, mobile and gaming applications, content *distribution**
- **Amazon S3 Standard-Infrequent Access (IA)** **Use Case: Disaster recovery, backups**
- **Amazon S3 One Zone-Infrequent Access**
- **Amazon S3 Glacier Instant Retrieval** 
- **Amazon S3 Glacier Flexible Retrieval**  Expedited: 1 to 5 minutes, Standard: 3 to 5 hours, Bulk 5 to 12 hours-free Minimum storage duration 90 days
- **Amazon S3 Glacier Deep Archive** Long term storage  standard: 12 hours, bulk 48 hours. Minimum storage duration 180 days
- **Amazon S3 Intelligent Tiering**

> Except for standard and intelligent u pay for object retrieval cost


# S3 requester Pays
# S3 – Requester Pays

- In general, bucket owners pay for all Amazon S3 storage and data transfer costs associated with their bucket.
- With **Requester Pays buckets**, the requester (instead of the bucket owner) pays the cost of the request and the data download from the bucket.
- Helpful when you want to share large datasets with other accounts.
- The requester must be authenticated in AWS (cannot be anonymous).


## S3 Event Notifications
In case an event send notifications (trigger):
- SNS
- SQS
- Lambda haha
- NEW EVEN AMAZON EVENTBRIDGE
> You can create as many S3 events as desired

# S3 Batch Operations

- Perform bulk operations on existing S3 objects with a single request. Examples:
  - Modify object metadata & properties
  - Copy objects between S3 buckets
  - Encrypt un-encrypted objects
  - Modify ACLs, tags
  - Restore objects from S3 Glacier
  - Invoke Lambda function to perform custom action on each object

- A job consists of a list of objects, the action to perform, and optional parameters.
- S3 Batch Operations manage retries, track progress, send completion notifications, and generate reports.
- You can use **S3 Inventory** to get object lists and use **S3 Select** to filter your objects.


# S3 – Storage Lens

- Understand, analyze, and optimize storage across the entire AWS Organization.
- Discover anomalies, identify cost efficiencies, and apply data protection best practices across the entire AWS Organization (30 days usage & activity metrics).
- Aggregate data for Organization, specific accounts, regions, buckets, or prefixes.
- Use the default dashboard or create your own dashboards.
- Can be configured to export metrics daily to an S3 bucket (CSV, Parquet).

# S3 Transfer acceleration
S3 Transfer Acceleration is a feature of Amazon S3 that speeds up the upload and download of objects over long distances by utilizing Amazon CloudFront’s globally distributed network of edge locations. This feature is particularly useful if you have users or applications located far from your S3 bucket's region, as it significantly reduces the time it takes to transfer data to and from S3.

# S3 SELECT

>S3 Select is a feature of Amazon S3 that allows you to query and retrieve only a subset of data from an object stored in an S3 bucket, instead of having to retrieve the entire object. This can help reduce the amount of data transferred and improve performance and cost efficiency, especially when working with large datasets.

# S3 Analytics (Storage Class Analysis)

    Use Case: Helps analyze storage patterns to optimize cost by determining when to transition data to more cost-effective storage classes (like S3 Infrequent Access or Glacier).
    Difference: Provides insights into the frequency of data access to suggest more optimal storage classes.

# S3 Inventory

    Use Case: Generates a daily or weekly report on the objects stored in an S3 bucket. This helps with auditing, compliance, and data management.
    Difference: A reporting tool for a detailed list of objects and their metadata, making it easier to track, audit, and manage S3 objects.

# S3 Storage Lens

    Use Case: Provides visibility into storage usage and activity trends across all accounts and regions with actionable recommendations for cost optimization, security, and compliance.
    Difference: It is a broader, multi-account, and multi-bucket tool for analyzing storage trends, efficiency, and security practices, offering dashboards and detailed insights.


# Summary
Summary of Differences:

    S3 Analytics: Focuses on analyzing data access to optimize storage classes. Storage Class Analysis
    S3 Inventory: Provides object-level reports for auditing and management. Reporting and Auding tool
    S3 Storage Lens: Delivers high-level storage visibility and recommendations across multiple accounts and regions.


# Amazon S3 – Object Encryption

You can encrypt objects in S3 buckets using one of 4 methods:

### Server-Side Encryption (SSE)

- **Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)** – *Enabled by Default*
  - Encrypts S3 objects using keys handled, managed, and owned by AWS.

- **Server-Side Encryption with KMS Keys stored in AWS KMS (SSE-KMS)**
  - Leverage AWS Key Management Service (AWS KMS) to manage encryption keys.

- **Server-Side Encryption with Customer-Provided Keys (SSE-C)**
  - When you want to manage your own encryption keys.

### Client-Side Encryption

---

It's important to understand which ones are for which situation for the exam.


## Amazon S3 Encryption – SSE-S3

- Encryption using keys handled, managed, and owned by AWS
- Object is encrypted server-side
- Encryption type is AES-256
- Must set header `"x-amz-server-side-encryption": "AES256"`
- Enabled by default for new buckets & new objects


## Amazon S3 Encryption – SSE-KMS

- Encryption using keys handled and managed by AWS KMS (Key Management Service)
- KMS advantages: user control + audit key usage using CloudTrail
- Object is encrypted server-side
- Must set header `"x-amz-server-side-encryption": "aws:kms"`


# Amazon S3 Encryption – SSE-C

- Server-Side Encryption using keys fully managed by the customer outside of AWS.
- Amazon S3 does **NOT** store the encryption key you provide.
- **HTTPS** must be used.
- Encryption key must be provided in HTTP headers for every HTTP request made.


# Amazon S3 Encryption – Client-Side Encryption

- Use client libraries such as **Amazon S3 Client-Side Encryption Library**.
- Clients must encrypt data themselves before sending to Amazon S3.
- Clients must decrypt data themselves when retrieving from Amazon S3.
- Customer fully manages the keys and encryption cycle.


# Amazon S3 – Encryption in transit (SSL/TLS)

- Encryption in flight is also called **SSL/TLS**.
- Amazon S3 exposes two endpoints:
  - **HTTP Endpoint** – non-encrypted
  - **HTTPS Endpoint** – encryption in flight
- **HTTPS is recommended**.
- **HTTPS is mandatory for SSE-C**.
- Most clients would use the HTTPS endpoint by default.

> Force encryption in Transit with deny policy condition aws_securetransport: false


> Force encryption with bucet policy
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Action": "s3:PutObject",
      "Principal": "*",
      "Resource": "arn:aws:s3:::my-bucket/*",
      "Condition": {
        "StringNotEquals": {
          "s3:x-amz-server-side-encryption": "aws:kms"
        }
      }
    }
  ]
}


> Bucket policies are avaliated before "Default Encryption"



# CORS (Cross origin resource sharing)

CORS is a webbrowser security that alows you to enable images or assets or files being retrieved

from one S3 bucket in case the request is originating

from another origin. One s3 is refering tex images that is stored in other s3 bucket. That bucket most allow access controll allow origin for the first 



# Amazon S3 – MFA Delete

- **MFA (Multi-Factor Authentication)** – forces users to generate a code on a device (usually a mobile phone or hardware) before doing important operations on S3.
  
- **MFA will be required to**:
  - Permanently delete an object version.
  - Suspend versioning on the bucket.

- **MFA won’t be required to**:
  - Enable versioning.
  - List deleted versions.

- To use MFA Delete, **Versioning** must be enabled on the bucket.

> - Only the bucket owner (root account) can enable/disable MFA Delete.
> You have use sdk or cli, not possible from the console


# Amazon S3 – Pre-Signed URLs

- Generate pre-signed URLs using the S3 Console, AWS CLI, or SDK.

## URL Expiration:
- **S3 Console**: 1 min up to 720 mins (12 hours).
- **AWS CLI**: Configure expiration with `--expires-in` parameter in seconds 
  (default 3600 secs, max. 604800 secs ~ 168 hours).

- Users given a pre-signed URL inherit the permissions of the user that generated the URL for GET/PUT.

## Examples:
- Allow only logged-in users to download a premium video from your S3 bucket.
- Allow an ever-changing list of users to download files by generating URLs dynamically.
- Allow temporarily a user to upload a file to a precise location in your S3 bucket.

# S3 Glacier Vault Lock

- Adopt a WORM (Write Once Read Many) model
- Create a Vault Lock Policy
- Lock the policy for future edits (can no longer be changed or deleted)
- Helpful for compliance and data retention



# S3 object lock (Versionin must be enable)

  - S3 Object Lock can help prevent Amazon S3 objects from being deleted or overwritten for a fixed amount of time or indefinitely. You must enable versioning
  - Object Lock provides two ways to manage object retention: retention periods and legal holds. An object version can have a retention period, a legal hold, or both.
      - Retention period – A retention period specifies a fixed period of time during which an object remains locked.
          -In compliance mode, a protected object version can't be overwritten or deleted by any user, including the root user in your AWS account. When an object is locked in compliance mode, its retention mode can't be changed, and its retention period can't be shortened. Compliance mode helps ensure that an object version can't be overwritten or deleted for the duration of the retention period.
          - In governance mode, users can't overwrite or delete an object version or alter its lock settings unless they have special permissions. With governance mode, you protect objects against being deleted by most users, but you can still grant some users permission to alter the retention settings or delete the objects if necessary. You can also use governance mode to test retention-period settings before creating a compliance-mode retention period. 
      - Legal hold -  legal hold provides the same protection as a retention period, but it has no expiration date. Instead, a legal hold remains in place until you explicitly remove it. Legal holds are independent from retention periods and are placed on individual object versions.

## Key Differences:

| Feature                | S3 Object Lock                           | S3 Glacier Vault Lock                      |
|------------------------|------------------------------------------|--------------------------------------------|
| **Scope**              | Individual S3 objects                    | Entire vault of archives                   |
| **Service**            | S3 Standard, S3 IA, etc.                 | S3 Glacier, S3 Glacier Deep Archive        |
| **Granularity**        | Per-object lock                          | Vault-wide lock                            |
| **Use Case**           | General purpose file immutability        | Archival immutability for long-term storage|
| **Modification/Deletion** | Retention period or legal hold based   | Locked policy can't be modified once set   |
| **Retention Modes**    | Governance Mode, Compliance Mode         | Vault-wide compliance, no modification after|
| **Primary Use Case**   | Short/medium term file protection        | Long-term archival and compliance          |

### Summary:

- **S3 Object Lock** is ideal for protecting individual objects in S3 buckets, often for shorter-term retention.
- **S3 Glacier Vault Lock** is designed for long-term archival storage, ensuring that the entire vault of data is protected according to strict, immutable policies that cannot be changed once applied.



# S3 access points

Using access point policy (similar to bucket policy),  u give permission the different folders in a bucket. Text sales, finance osv.
- Access points simplify security management for s3 buckets
- Each  access points has its own dns name (internet or vpc (private))

## S3 – Access Points – VPC Origin

- **Access Point Restriction**: We can define the access point to be accessible only from within the VPC.
- **VPC Endpoint Requirement**: You must create a VPC Endpoint to access the access point (either Gateway or Interface Endpoint).
- **Endpoint Policy**: The VPC Endpoint Policy must allow access to the target bucket and Access Point.


## Endpoints 
A VPC Endpoint in AWS allows you to privately connect your Virtual Private Cloud (VPC) to supported AWS services and VPC endpoint services without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect. Essentially, a VPC Endpoint enables secure, private communications between your VPC and AWS services without exposing the traffic to the public internet.
Types of VPC Endpoints

    Interface Endpoint:
        An Elastic Network Interface (ENI) in your VPC with a private IP address that serves as an entry point for traffic destined for the AWS service.
        Supports most AWS services (e.g., S3, EC2, KMS, and Lambda).
        Allows communication over private IP addresses within the VPC.
    Gateway Endpoint:
        Acts as a target for a route in your route table for S3 and DynamoDB services.
        Does not use Elastic Network Interfaces but instead allows routing traffic for S3 and DynamoDB directly through the private route table in your VPC.

> Conclusion:

    Gateway Endpoints are limited to Amazon S3 and DynamoDB.
    Interface Endpoints are available for many other AWS services like Lambda, STS, EC2 API, KMS, and more.


# S3 Object Lambda

- Use AWS Lambda Functions to change the object before it is retrieved by the caller application.
- Only one S3 bucket is needed, on top of which we create S3 Access Point and S3 Object Lambda Access Points.

### Use Cases:
## S3 Object Lambda Access Point:

    Purpose: Allows you to transform and process S3 objects on the fly using AWS Lambda functions. This enables customizations or modifications to the object as it is being retrieved by the caller application.
    How it works:
        When an application requests an object via an S3 Object Lambda Access Point, a Lambda function intercepts the request.
        The Lambda function can modify or transform the object (e.g., redact sensitive information, convert formats, resize images) before sending the object back to the client.
    Key Use Case: Enables dynamic transformations, like:
        Redacting personally identifiable information (PII).
        Converting between formats, like XML to JSON.
        Image resizing and watermarking based on request-specific parameters.
    Configuration: You configure an S3 Object Lambda Access Point by associating it with a Lambda function and an underlying S3 Access Point.
- Redacting personally identifiable information for analytics or non-production environments.
- Converting across data formats, such as converting XML to JSON.
- Resizing and watermarking images on the fly using caller-specific details, such as the user who requested the object.

